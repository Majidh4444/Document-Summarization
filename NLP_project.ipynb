{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6b0efc8",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# 19CSE453 Natural Language Processing\n",
    "## Document Summarization \n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560dd437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce6f054a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\kmaji\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\kmaji\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\kmaji\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kmaji\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kmaji\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kmaji\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b111ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kmaji\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3566f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
    "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
    "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[3] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48383e11",
   "metadata": {},
   "source": [
    "## Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30199f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'are', 'broadly', 'two', 'types', 'of', 'extractive', 'summarization', 'tasks', 'depending', 'on', 'what', 'the', 'summarization', 'program', 'focuses', 'on', '.', 'The', 'first', 'is', 'generic', 'summarization', ',', 'which', 'focuses', 'on', 'obtaining', 'a', 'generic', 'summary', 'or', 'abstract', 'of', 'the', 'collection', '(', 'whether', 'documents', ',', 'or', 'sets', 'of', 'images', ',', 'or', 'videos', ',', 'news', 'stories', 'etc.', ')', '.', 'The', 'second', 'is', 'query', 'relevant', 'summarization', ',', 'sometimes', 'called', 'query-based', 'summarization', ',', 'which', 'summarizes', 'objects', 'specific', 'to', 'a', 'query', '.', 'Summarization', 'systems', 'are', 'able', 'to', 'create', 'both', 'query', 'relevant', 'text', 'summaries', 'and', 'generic', 'machine-generated', 'summaries', 'depending', 'on', 'what', 'the', 'user', 'needs', '.', 'An', 'example', 'of', 'a', 'summarization', 'problem', 'is', 'document', 'summarization', ',', 'which', 'attempts', 'to', 'automatically', 'produce', 'an', 'abstract', 'from', 'a', 'given', 'document', '.', 'Sometimes', 'one', 'might', 'be', 'interested', 'in', 'generating', 'a', 'summary', 'from', 'a', 'single', 'source', 'document', ',', 'while', 'others', 'can', 'use', 'multiple', 'source', 'documents', '(', 'for', 'example', ',', 'a', 'cluster', 'of', 'articles', 'on', 'the', 'same', 'topic', ')', '.', 'This', 'problem', 'is', 'called', 'multi-document', 'summarization', '.', 'A', 'related', 'application', 'is', 'summarizing', 'news', 'articles', '.', 'Imagine', 'a', 'system', ',', 'which', 'automatically', 'pulls', 'together', 'news', 'articles', 'on', 'a', 'given', 'topic', '(', 'from', 'the', 'web', ')', ',', 'and', 'concisely', 'represents', 'the', 'latest', 'news', 'as', 'a', 'summary', '.', 'Image', 'collection', 'summarization', 'is', 'another', 'application', 'example', 'of', 'automatic', 'summarization', '.', 'It', 'consists', 'in', 'selecting', 'a', 'representative', 'set', 'of', 'images', 'from', 'a', 'larger', 'set', 'of', 'images', '.', '[', '3', ']', 'A', 'summary', 'in', 'this', 'context', 'is', 'useful', 'to', 'show', 'the', 'most', 'representative', 'images', 'of', 'results', 'in', 'an', 'image', 'collection', 'exploration', 'system', '.', 'Video', 'summarization', 'is', 'a', 'related', 'domain', ',', 'where', 'the', 'system', 'automatically', 'creates', 'a', 'trailer', 'of', 'a', 'long', 'video', '.', 'This', 'also', 'has', 'applications', 'in', 'consumer', 'or', 'personal', 'videos', ',', 'where', 'one', 'might', 'want', 'to', 'skip', 'the', 'boring', 'or', 'repetitive', 'actions', '.', 'Similarly', ',', 'in', 'surveillance', 'videos', ',', 'one', 'would', 'want', 'to', 'extract', 'important', 'and', 'suspicious', 'activity', ',', 'while', 'ignoring', 'all', 'the', 'boring', 'and', 'redundant', 'frames', 'captured', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_word = word_tokenize(text)\n",
    "print(tokenized_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deddbab",
   "metadata": {},
   "source": [
    "## Stop Words  & Punctuations Removing (Text Cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cd0725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kmaji\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eight',\n",
       " 'few',\n",
       " 'five',\n",
       " 'for',\n",
       " 'four',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'seven',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'six',\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'three',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'two',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "additional_stopwords = {\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten'\n",
    "}\n",
    "stop_words.update(additional_stopwords)\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9ae115b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'+', '$', ']', '>', '[', '(', '*', '?', '%', '`', ':', '_', '=', '\\\\', ',', ';', '/', '&', '-', '{', '#', '\"', \"'\", '@', '~', '<', ')', '|', '.', '}', '!', '\\n', '^'}\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "punctuation = set(string.punctuation) # Access punctuation characters from the string module\n",
    "punctuation.add('\\n')\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86be7b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'broadly': 1,\n",
       "             'types': 1,\n",
       "             'extractive': 1,\n",
       "             'summarization': 11,\n",
       "             'tasks': 1,\n",
       "             'depending': 2,\n",
       "             'program': 1,\n",
       "             'focuses': 2,\n",
       "             'first': 1,\n",
       "             'generic': 3,\n",
       "             'obtaining': 1,\n",
       "             'summary': 4,\n",
       "             'abstract': 2,\n",
       "             'collection': 3,\n",
       "             'whether': 1,\n",
       "             'documents': 2,\n",
       "             'sets': 1,\n",
       "             'images': 4,\n",
       "             'videos': 3,\n",
       "             'news': 4,\n",
       "             'stories': 1,\n",
       "             'etc.': 1,\n",
       "             'second': 1,\n",
       "             'query': 3,\n",
       "             'relevant': 2,\n",
       "             'sometimes': 1,\n",
       "             'called': 2,\n",
       "             'query-based': 1,\n",
       "             'summarizes': 1,\n",
       "             'objects': 1,\n",
       "             'specific': 1,\n",
       "             'Summarization': 1,\n",
       "             'systems': 1,\n",
       "             'able': 1,\n",
       "             'create': 1,\n",
       "             'text': 1,\n",
       "             'summaries': 2,\n",
       "             'machine-generated': 1,\n",
       "             'user': 1,\n",
       "             'needs': 1,\n",
       "             'example': 3,\n",
       "             'problem': 2,\n",
       "             'document': 3,\n",
       "             'attempts': 1,\n",
       "             'automatically': 3,\n",
       "             'produce': 1,\n",
       "             'given': 2,\n",
       "             'Sometimes': 1,\n",
       "             'might': 2,\n",
       "             'interested': 1,\n",
       "             'generating': 1,\n",
       "             'single': 1,\n",
       "             'source': 2,\n",
       "             'others': 1,\n",
       "             'use': 1,\n",
       "             'multiple': 1,\n",
       "             'cluster': 1,\n",
       "             'articles': 3,\n",
       "             'topic': 2,\n",
       "             'multi-document': 1,\n",
       "             'related': 2,\n",
       "             'application': 2,\n",
       "             'summarizing': 1,\n",
       "             'Imagine': 1,\n",
       "             'system': 3,\n",
       "             'pulls': 1,\n",
       "             'together': 1,\n",
       "             'web': 1,\n",
       "             'concisely': 1,\n",
       "             'represents': 1,\n",
       "             'latest': 1,\n",
       "             'Image': 1,\n",
       "             'another': 1,\n",
       "             'automatic': 1,\n",
       "             'consists': 1,\n",
       "             'selecting': 1,\n",
       "             'representative': 2,\n",
       "             'set': 2,\n",
       "             'larger': 1,\n",
       "             'context': 1,\n",
       "             'useful': 1,\n",
       "             'show': 1,\n",
       "             'results': 1,\n",
       "             'image': 1,\n",
       "             'exploration': 1,\n",
       "             'Video': 1,\n",
       "             'domain': 1,\n",
       "             'creates': 1,\n",
       "             'trailer': 1,\n",
       "             'long': 1,\n",
       "             'video': 1,\n",
       "             'also': 1,\n",
       "             'applications': 1,\n",
       "             'consumer': 1,\n",
       "             'personal': 1,\n",
       "             'want': 2,\n",
       "             'skip': 1,\n",
       "             'boring': 2,\n",
       "             'repetitive': 1,\n",
       "             'actions': 1,\n",
       "             'Similarly': 1,\n",
       "             'surveillance': 1,\n",
       "             'would': 1,\n",
       "             'extract': 1,\n",
       "             'important': 1,\n",
       "             'suspicious': 1,\n",
       "             'activity': 1,\n",
       "             'ignoring': 1,\n",
       "             'redundant': 1,\n",
       "             'frames': 1,\n",
       "             'captured': 1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "word_frequencies = defaultdict(int)\n",
    "\n",
    "for w in tokenized_word:\n",
    "    if w.lower() not in stop_words:\n",
    "        if w.lower() not in punctuation:\n",
    "            if w not in word_frequencies.keys():\n",
    "                word_frequencies[w] = 1\n",
    "            else:\n",
    "                word_frequencies[w] += 1\n",
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f03ed3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Normalizing all frequencies using max_frequency\n",
    "max_frequency = max(word_frequencies.values())\n",
    "max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ab9fab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'broadly': 0.09090909090909091,\n",
       "             'types': 0.09090909090909091,\n",
       "             'extractive': 0.09090909090909091,\n",
       "             'summarization': 1.0,\n",
       "             'tasks': 0.09090909090909091,\n",
       "             'depending': 0.18181818181818182,\n",
       "             'program': 0.09090909090909091,\n",
       "             'focuses': 0.18181818181818182,\n",
       "             'first': 0.09090909090909091,\n",
       "             'generic': 0.2727272727272727,\n",
       "             'obtaining': 0.09090909090909091,\n",
       "             'summary': 0.36363636363636365,\n",
       "             'abstract': 0.18181818181818182,\n",
       "             'collection': 0.2727272727272727,\n",
       "             'whether': 0.09090909090909091,\n",
       "             'documents': 0.18181818181818182,\n",
       "             'sets': 0.09090909090909091,\n",
       "             'images': 0.36363636363636365,\n",
       "             'videos': 0.2727272727272727,\n",
       "             'news': 0.36363636363636365,\n",
       "             'stories': 0.09090909090909091,\n",
       "             'etc.': 0.09090909090909091,\n",
       "             'second': 0.09090909090909091,\n",
       "             'query': 0.2727272727272727,\n",
       "             'relevant': 0.18181818181818182,\n",
       "             'sometimes': 0.09090909090909091,\n",
       "             'called': 0.18181818181818182,\n",
       "             'query-based': 0.09090909090909091,\n",
       "             'summarizes': 0.09090909090909091,\n",
       "             'objects': 0.09090909090909091,\n",
       "             'specific': 0.09090909090909091,\n",
       "             'Summarization': 0.09090909090909091,\n",
       "             'systems': 0.09090909090909091,\n",
       "             'able': 0.09090909090909091,\n",
       "             'create': 0.09090909090909091,\n",
       "             'text': 0.09090909090909091,\n",
       "             'summaries': 0.18181818181818182,\n",
       "             'machine-generated': 0.09090909090909091,\n",
       "             'user': 0.09090909090909091,\n",
       "             'needs': 0.09090909090909091,\n",
       "             'example': 0.2727272727272727,\n",
       "             'problem': 0.18181818181818182,\n",
       "             'document': 0.2727272727272727,\n",
       "             'attempts': 0.09090909090909091,\n",
       "             'automatically': 0.2727272727272727,\n",
       "             'produce': 0.09090909090909091,\n",
       "             'given': 0.18181818181818182,\n",
       "             'Sometimes': 0.09090909090909091,\n",
       "             'might': 0.18181818181818182,\n",
       "             'interested': 0.09090909090909091,\n",
       "             'generating': 0.09090909090909091,\n",
       "             'single': 0.09090909090909091,\n",
       "             'source': 0.18181818181818182,\n",
       "             'others': 0.09090909090909091,\n",
       "             'use': 0.09090909090909091,\n",
       "             'multiple': 0.09090909090909091,\n",
       "             'cluster': 0.09090909090909091,\n",
       "             'articles': 0.2727272727272727,\n",
       "             'topic': 0.18181818181818182,\n",
       "             'multi-document': 0.09090909090909091,\n",
       "             'related': 0.18181818181818182,\n",
       "             'application': 0.18181818181818182,\n",
       "             'summarizing': 0.09090909090909091,\n",
       "             'Imagine': 0.09090909090909091,\n",
       "             'system': 0.2727272727272727,\n",
       "             'pulls': 0.09090909090909091,\n",
       "             'together': 0.09090909090909091,\n",
       "             'web': 0.09090909090909091,\n",
       "             'concisely': 0.09090909090909091,\n",
       "             'represents': 0.09090909090909091,\n",
       "             'latest': 0.09090909090909091,\n",
       "             'Image': 0.09090909090909091,\n",
       "             'another': 0.09090909090909091,\n",
       "             'automatic': 0.09090909090909091,\n",
       "             'consists': 0.09090909090909091,\n",
       "             'selecting': 0.09090909090909091,\n",
       "             'representative': 0.18181818181818182,\n",
       "             'set': 0.18181818181818182,\n",
       "             'larger': 0.09090909090909091,\n",
       "             'context': 0.09090909090909091,\n",
       "             'useful': 0.09090909090909091,\n",
       "             'show': 0.09090909090909091,\n",
       "             'results': 0.09090909090909091,\n",
       "             'image': 0.09090909090909091,\n",
       "             'exploration': 0.09090909090909091,\n",
       "             'Video': 0.09090909090909091,\n",
       "             'domain': 0.09090909090909091,\n",
       "             'creates': 0.09090909090909091,\n",
       "             'trailer': 0.09090909090909091,\n",
       "             'long': 0.09090909090909091,\n",
       "             'video': 0.09090909090909091,\n",
       "             'also': 0.09090909090909091,\n",
       "             'applications': 0.09090909090909091,\n",
       "             'consumer': 0.09090909090909091,\n",
       "             'personal': 0.09090909090909091,\n",
       "             'want': 0.18181818181818182,\n",
       "             'skip': 0.09090909090909091,\n",
       "             'boring': 0.18181818181818182,\n",
       "             'repetitive': 0.09090909090909091,\n",
       "             'actions': 0.09090909090909091,\n",
       "             'Similarly': 0.09090909090909091,\n",
       "             'surveillance': 0.09090909090909091,\n",
       "             'would': 0.09090909090909091,\n",
       "             'extract': 0.09090909090909091,\n",
       "             'important': 0.09090909090909091,\n",
       "             'suspicious': 0.09090909090909091,\n",
       "             'activity': 0.09090909090909091,\n",
       "             'ignoring': 0.09090909090909091,\n",
       "             'redundant': 0.09090909090909091,\n",
       "             'frames': 0.09090909090909091,\n",
       "             'captured': 0.09090909090909091})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in word_frequencies:\n",
    "    word_frequencies[word] = word_frequencies[word] / max_frequency\n",
    "word_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2e9c3",
   "metadata": {},
   "source": [
    "## Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c68ae95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.', 'The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).', 'The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.', 'Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.', 'An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.', 'Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).', 'This problem is called multi-document summarization.', 'A related application is summarizing news articles.', 'Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.', 'Image collection summarization is another application example of automatic summarization.', 'It consists in selecting a representative set of images from a larger set of images.', '[3] A summary in this context is useful to show the most representative images of results in an image collection exploration system.', 'Video summarization is a related domain, where the system automatically creates a trailer of a long video.', 'This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.', 'Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentence = sent_tokenize(text)\n",
    "print(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47f78e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. \n",
      " 2.818181818181818 \n",
      "\n",
      "The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). \n",
      " 2.2727272727272725 \n",
      "\n",
      "The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. \n",
      " 1.1818181818181817 \n",
      "\n",
      "Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs. \n",
      " 2.8181818181818175 \n",
      "\n",
      "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. \n",
      " 2.545454545454545 \n",
      "\n",
      "Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). \n",
      " 2.090909090909091 \n",
      "\n",
      "This problem is called multi-document summarization. \n",
      " 0.4545454545454546 \n",
      "\n",
      "A related application is summarizing news articles. \n",
      " 0.8181818181818182 \n",
      "\n",
      "Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary. \n",
      " 2.090909090909091 \n",
      "\n",
      "Image collection summarization is another application example of automatic summarization. \n",
      " 2.0 \n",
      "\n",
      "It consists in selecting a representative set of images from a larger set of images. \n",
      " 1.1818181818181819 \n",
      "\n",
      "[3] A summary in this context is useful to show the most representative images of results in an image collection exploration system. \n",
      " 1.7272727272727273 \n",
      "\n",
      "Video summarization is a related domain, where the system automatically creates a trailer of a long video. \n",
      " 2.090909090909091 \n",
      "\n",
      "This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. \n",
      " 1.0909090909090908 \n",
      "\n",
      "Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured. \n",
      " 1.0909090909090908 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentence_scores = {}  # Use a dictionary to store sentence scores\n",
    "\n",
    "for sent in tokenized_sentence:\n",
    "    score = 0  # Initialize the score for the current sentence\n",
    "    words = sent.split()\n",
    "    for word in words:\n",
    "        if word.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_frequencies[word.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_frequencies[word.lower()]\n",
    "    print(sent, \"\\n\", sentence_scores[sent],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0e5cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae9f0fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_length = int(len(tokenized_sentence)*0.3)\n",
    "select_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a55b9099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.',\n",
       " 'Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.',\n",
       " 'An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.',\n",
       " 'The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf15b51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.', 'Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.', 'An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.', 'The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).']\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
